{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osnabrück University - A&C: Computational Cognition (Summer Term 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 05: Eye tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in at 14:00 at **Tuesday, May 28, 2019**. If you need help (and Google and other resources were not enough), feel free to contact your tutors. Please push your results to your Github group folder.\n",
    "\n",
    "For this exercise sheet you will have 2 weeks and the sheet is also worth of 30 points. In this exercise sheet you will start to work with eye tracking data. Note that the data we will use here are not raw gaze data and contain coordinates of fixation points.\n",
    "\n",
    "The dataset is distributed freely by a following study: [Wilming, N. Dryad](https://www.nature.com/articles/sdata2016126#data-citations). By clicking on the link in the section \"Data Citations\" you will get redirected to the page where you can download all the data openly distributed. Read below for description of each file.\n",
    "\n",
    "##### necessary\n",
    "*etdb_v1.0*: This is the main data file. The hdf5 file consists of all the fixation data and the metadata.  \n",
    "*Read gaze data with python*: Python script to read hdf5 file as a dataframe.  \n",
    "*Stimuli/i*: Zip file containing image stimuli used in the study. The encoding convention is same as in the dataframe.\n",
    "##### optional\n",
    "*Metadata*: This is the csv file giving overview of all studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install h5py # make sure to install h5py which is used in fixmat.py\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "%pip install h5py # make sure to install h5py which is used in fixmat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import *\n",
    "from datas.fixmat import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 0: Peer review for sheet 04 [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each group reviews the solutions of two other groups and give points according to the given point distribution considering the correctness of the solution. For this reviews the tutors will give you up to 3 points each week. Follow a distributed comment guidelines if you are unsure.\n",
    "\n",
    "| * |Group 1|Group 2|Group 3|Group 4|Group 5|Group 6|Group 7|Group 8|Group 9|Group 10|Group 11|\n",
    "| ------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ------ | ------ |\n",
    "| check solutions of group: | 5, 9 | 1, 6  | 4, 7  | 7, 2 | 2, 11 | 8, 3 | 3, 10  | 11, 1  | 10, 4  | 6, 8  | 9, 5   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Checking the data distribution [9 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) loading datasets [0 pts]\n",
    "As with any other datasets, the first step is to get an idea of the dataset. Check the meta data and column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a fixmat.py to load the hdf5 format data as a panda dataframe\n",
    "df, meta = load('datas/etdb_v1.0.hdf5', \"Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Task': 'FV',\n",
       " '# Obs.': 48,\n",
       " 'V. dist. (cm) ': 80,\n",
       " 'V. Dur.': '6s',\n",
       " 'Article': 15.0,\n",
       " 'Display resolution (pixels)': '1280x960',\n",
       " 'Val. error (degrees)': 0.3,\n",
       " 'ID': 3,\n",
       " 'Categories': '7,8,10,11',\n",
       " 'Sampling freq. (Hz)': '500 Hz',\n",
       " 'PPD': 45.6,\n",
       " 'Eye Tracker': 'EL II',\n",
       " 'Age': '23.1 (19-28)',\n",
       " 'Img. Pos. (pixel)': '0,0',\n",
       " 'Disp. Size (degree)': '29x22',\n",
       " 'Display': 'SM1100',\n",
       " 'Img. size (pixel)': '1280x960',\n",
       " '# Fix.': 203772}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SUBJECTINDEX', 'category', 'dataset_nr', 'end', 'eye', 'filenumber',\n",
       "       'fix', 'pupil', 'start', 'trial', 'x', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) data cleaning [3 pts]\n",
    "We want to clean the dataframe so that it is handy for us to work with it.\n",
    "- How many fixations do we have per category? ```agg``` function might be helpful.\n",
    "- categories are encoded using a number. Add a column to the dataframe that has approporiate string value for that category (e.g. code 11.0 to \"Pink-noise\"). The category names can be found on Figure 2 of the paper.\n",
    "- since measurements lasted for 6 seconds, any fixation points that have a onset time before 0 sec and end time more than 6 sec are erroneous. Remove these rows.\n",
    "- also remove all rows with any NaN values.\n",
    "- add a column called ```duration``` and compute the duration of each fixation.\n",
    "- It is known from previous literature that fixations typically last between 100 msec to 400 msec. Remove all rows with unrealistic  fixation duration.\n",
    "- check how many data points got removed for each category. Let's hope that we didn't delete too many rows from a single category.\n",
    "- count the number of fixations for each trial. To do this, you can use the aggregate method to count the number of rows for each category.\n",
    "- print the mean duration and the mean number of fixation across all trials. Are they in a realistic range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixations for Nature:\n",
      "          fix\n",
      "sum  525239.0\n",
      " \n",
      "Fixations for Urban:\n",
      "          fix\n",
      "sum  603065.0\n",
      " \n",
      "Fixations for Fractal:\n",
      "          fix\n",
      "sum  535803.0\n",
      " \n",
      "Fixations for Pink-Noise:\n",
      "          fix\n",
      "sum  369649.0\n",
      " \n",
      "Number of rows deleted for Nature:\n",
      "12554\n",
      " \n",
      "Number of rows deleted for Urban:\n",
      "11835\n",
      " \n",
      "Number of rows deleted for Fractal:\n",
      "12979\n",
      " \n",
      "Number of rows deleted for Pink-Noise:\n",
      "14603\n",
      "1           1.0\n",
      "2           1.0\n",
      "3           1.0\n",
      "4           1.0\n",
      "6           1.0\n",
      "7           1.0\n",
      "8           1.0\n",
      "10          1.0\n",
      "11          1.0\n",
      "12          1.0\n",
      "13          1.0\n",
      "14          1.0\n",
      "15          1.0\n",
      "16          1.0\n",
      "17          1.0\n",
      "20          2.0\n",
      "21          2.0\n",
      "22          2.0\n",
      "23          2.0\n",
      "24          2.0\n",
      "25          2.0\n",
      "26          2.0\n",
      "27          2.0\n",
      "28          2.0\n",
      "29          2.0\n",
      "30          2.0\n",
      "31          2.0\n",
      "32          2.0\n",
      "33          2.0\n",
      "34          2.0\n",
      "          ...  \n",
      "203734    254.0\n",
      "203735    254.0\n",
      "203736    254.0\n",
      "203737    254.0\n",
      "203738    254.0\n",
      "203740    254.0\n",
      "203741    254.0\n",
      "203742    254.0\n",
      "203743    254.0\n",
      "203745    254.0\n",
      "203746    254.0\n",
      "203747    254.0\n",
      "203749    254.0\n",
      "203750    254.0\n",
      "203751    254.0\n",
      "203752    254.0\n",
      "203753    254.0\n",
      "203754    255.0\n",
      "203755    255.0\n",
      "203757    255.0\n",
      "203758    255.0\n",
      "203760    255.0\n",
      "203762    255.0\n",
      "203763    255.0\n",
      "203765    255.0\n",
      "203766    255.0\n",
      "203767    255.0\n",
      "203768    255.0\n",
      "203769    255.0\n",
      "203770    255.0\n",
      "Name: trial, Length: 151801, dtype: float32\n",
      "Fixations for Nature:\n",
      "          fix\n",
      "sum  402658.0\n",
      " \n",
      "Fixations for Urban:\n",
      "          fix\n",
      "sum  479042.0\n",
      " \n",
      "Fixations for Fractal:\n",
      "          fix\n",
      "sum  408509.0\n",
      " \n",
      "Fixations for Pink-Noise:\n",
      "          fix\n",
      "sum  251724.0\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# create new column with category names\n",
    "df['categoryNames'] = df['category']\n",
    "df = df.replace({'categoryNames':{7:'Nature',8:'Urban',10:'Fractal',11:'Pink-Noise'}}, regex=True)\n",
    "# fixations per category\n",
    "fix_nature = df[df['categoryNames']=='Nature'].agg({'fix': [np.sum]})\n",
    "fix_urban = df[df['categoryNames']=='Urban'].agg({'fix': [np.sum]})\n",
    "fix_fractal = df[df['categoryNames']=='Fractal'].agg({'fix': [np.sum]})\n",
    "fix_pinknoise = df[df['categoryNames']=='Pink-Noise'].agg({'fix': [np.sum]})\n",
    "print(\"Fixations for Nature:\")\n",
    "print(fix_nature)\n",
    "print(\" \")\n",
    "print(\"Fixations for Urban:\")\n",
    "print(fix_urban)\n",
    "print(\" \")\n",
    "print(\"Fixations for Fractal:\")\n",
    "print(fix_fractal)\n",
    "print(\" \")\n",
    "print(\"Fixations for Pink-Noise:\")\n",
    "print(fix_pinknoise)\n",
    "print(\" \")\n",
    "\n",
    "clean_df = df[df['start'] >= 0]\n",
    "clean_df = clean_df[clean_df['end'] <= 6000].dropna()\n",
    "clean_df['duration'] = clean_df['end'] - clean_df['start']\n",
    "clean_df = clean_df[clean_df['duration'] <= 400]\n",
    "clean_df = clean_df[clean_df['duration'] >= 100]\n",
    "\n",
    "print(\"Number of rows deleted for Nature:\")\n",
    "print(len(df[df['categoryNames']=='Nature']) - len(clean_df[clean_df['categoryNames']=='Nature']))\n",
    "print(\" \")\n",
    "print(\"Number of rows deleted for Urban:\")\n",
    "print(len(df[df['categoryNames']=='Urban']) - len(clean_df[clean_df['categoryNames']=='Urban']))\n",
    "print(\" \")\n",
    "print(\"Number of rows deleted for Fractal:\")\n",
    "print(len(df[df['categoryNames']=='Fractal']) - len(clean_df[clean_df['categoryNames']=='Fractal']))\n",
    "print(\" \")\n",
    "print(\"Number of rows deleted for Pink-Noise:\")\n",
    "print(len(df[df['categoryNames']=='Pink-Noise']) - len(clean_df[clean_df['categoryNames']=='Pink-Noise']))\n",
    "\n",
    "print(clean_df['trial'])\n",
    "\n",
    "# fixations per category\n",
    "clean_fix_nature = clean_df[clean_df['categoryNames']=='Nature'].agg({'fix': [np.sum]})\n",
    "clean_fix_urban = clean_df[clean_df['categoryNames']=='Urban'].agg({'fix': [np.sum]})\n",
    "clean_fix_fractal = clean_df[clean_df['categoryNames']=='Fractal'].agg({'fix': [np.sum]})\n",
    "clean_fix_pinknoise = clean_df[clean_df['categoryNames']=='Pink-Noise'].agg({'fix': [np.sum]})\n",
    "print(\"Fixations for Nature:\")\n",
    "print(clean_fix_nature)\n",
    "print(\" \")\n",
    "print(\"Fixations for Urban:\")\n",
    "print(clean_fix_urban)\n",
    "print(\" \")\n",
    "print(\"Fixations for Fractal:\")\n",
    "print(clean_fix_fractal)\n",
    "print(\" \")\n",
    "print(\"Fixations for Pink-Noise:\")\n",
    "print(clean_fix_pinknoise)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) visualizing data distribution [3 pts]\n",
    "Are there any inter-subject difference and effect of different category in our data?\n",
    "- plot the mean duration for each category (4 x-values) and the mean duration for each subject (48 x-values).\n",
    "\n",
    "- plot the mean number of fixations for each category (4 x-values) and the mean number of fixation for each subject (48 x-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) normally distributed data [3 pts]\n",
    "As ANOVA and lots of other statistical tests can be used only for normally distributed varaibles, it makes sense to find out whether the fixation duration and the number of fixations per trial is also normally distributed. This can be done with a Q-Q-Plot, which  is a graphical technique for determining if two data sets come from populations with a common distribution, in this case a normal distribution (for more information, klick [here](https://www.itl.nist.gov/div898/handbook/eda/section3/eda33o.htm)).\n",
    "- make a Q-Q plot of the variable *fixation duration*. Is it approximately normally distributed?\n",
    "- make a Q-Q plot of the variable *# fixation per trial*. Is it approximately normally distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what do you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Hypothesis testing [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) one way ANOVA [3 pts]\n",
    "Now it's time to really prove our intuition. Test the following null hypotheses:  \n",
    "$H01$: There is no difference in fixation duration across 4 different categories.  \n",
    "$H02$: There is no difference in the number of fixations across 4 different categories.\n",
    "\n",
    "What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# H02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what do you say?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Binning [4 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) distribution of # fixation [2 pts]\n",
    "Now we would like to know if there's a difference in terms of fixation numbers at different time segment.\n",
    "- make a histogram with x axis being the start time of fixation\n",
    "- the bin size should be 1 sec. In total there would be 6 bins.\n",
    "- average over all subjects and images, just make a one simple plot\n",
    "- figure out mean fixation duration for each bin and print it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) leftward bias [2 pts]\n",
    "If you took Action & Cognition I, you have probably heard about the leftward bias in human's fixation behavior. It is known that people tend to look more at the left visual field for the initial first second. Check whether this holds for our dataset as well.\n",
    "- make a pointplot with x-axis as the x-coordinate of each fixation point and y-axis as the time bin to which the fixation point belongs to.\n",
    "- mark the confidence interval around each point.\n",
    "- make a vertical line at middle point of the x values. The x-coordinate of the fixation point in the data is based on the coordinate system using the display resolution. You can find out the information about display resolution by taking a look at the meta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4: Heatmap [4 pts]\n",
    "Now let's use heatmap to visualize which part of pictures is fixated for how long. It would be also good to know if there's a difference between categories.\n",
    "- make a heatmap for data consisting of each categories and then averaged across all data.\n",
    "- mark a central point in the plot.\n",
    "- you can use ```numpy.histogram2d``` to compute a bi-dimensional histogram.\n",
    "- then you can use ```pyplot.imshow``` to plot these histogram.\n",
    "- don't forget to use the parameter ```extent``` to control for the bounding box to which the image should fit in.\n",
    "- if you want to use other functions that's surely fine as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5: Scanpath [5 pts]\n",
    "We want to know whether different scan behaviour is used when viewing images of different categories. Scanpath is a path followed by the eyes when viewing a stimulus. Scanpaths are useful for analyzing cognitive intent, interest, and salience. It has an advantage to a heatmap because the information about temporal structure of viewing behaviour can be plotted.\n",
    "- make four plots, one for each category.\n",
    "- randomely choose one trial for which you will plot a scanpath.\n",
    "- mark fixation points based on the x-y coordinates.\n",
    "- plot the *saccade path* from one fixation point to another one.\n",
    "- make sure that the order of fixation can be read out from the plot. E.g. earlier fixations could have a light color whereas later fixations could have dark colors.\n",
    "- also include information about the duration of each fixation. One way to do it is the use the size of the fixation marker.\n",
    "- plot the background image superimposed with the scanpath. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation\n",
    "Wilming N, Onat S, Ossandón J, Acik A, Kietzmann TC, Kaspar K, Gameiro RR, Vormberg A, König P (2017) An extensive dataset of eye movements during viewing of complex images. Scientific Data 4: 160126. https://doi.org/10.1038/sdata.2016.126  \n",
    "Wilming N, Onat S, Ossandón J, Acik A, Kietzmann TC, Kaspar K, Gameiro RR, Vormberg A, König P (2017) Data from: An extensive dataset of eye movements during viewing of complex images. Dryad Digital Repository. https://doi.org/10.5061/dryad.9pf75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
